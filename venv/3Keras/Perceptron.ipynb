{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam # Adagrad and RMSprop  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0922 14:02:24.876004 16020 deprecation_wrapper.py:119] From c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0922 14:02:26.139696 16020 deprecation_wrapper.py:119] From c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0922 14:02:26.283728 16020 deprecation_wrapper.py:119] From c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0922 14:02:26.459768 16020 deprecation_wrapper.py:119] From c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0922 14:02:26.471777 16020 deprecation_wrapper.py:119] From c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0922 14:02:26.487775 16020 deprecation.py:323] From c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0922 14:02:27.594506 16020 deprecation_wrapper.py:119] From c:\\users\\karti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 1.4227 - acc: 0.5550\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.6338 - acc: 0.601 - 0s 178us/step - loss: 0.6247 - acc: 0.6120\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 0s 206us/step - loss: 0.4458 - acc: 0.8290\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 0s 212us/step - loss: 0.3837 - acc: 0.8950\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.3406 - acc: 0.9050\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 0s 217us/step - loss: 0.3077 - acc: 0.9270\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.2884 - acc: 0.9320\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.2609 - acc: 0.9390\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 0s 210us/step - loss: 0.2346 - acc: 0.9580\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 0s 158us/step - loss: 0.2190 - acc: 0.9630\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.2038 - acc: 0.9580\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 0s 131us/step - loss: 0.1924 - acc: 0.9600\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.1805 - acc: 0.9670\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.1713 - acc: 0.9680\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.1657 - acc: 0.9650\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 0s 208us/step - loss: 0.1576 - acc: 0.9670\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1560 - acc: 0.967 - 0s 148us/step - loss: 0.1497 - acc: 0.9690\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.1446 - acc: 0.9670\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.1388 - acc: 0.9760\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.1333 - acc: 0.9740\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 0s 283us/step - loss: 0.1311 - acc: 0.9740\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 0s 382us/step - loss: 0.1263 - acc: 0.9750 0s - loss: 0.1223 - acc: 0.98\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.1275 - acc: 0.9720\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 0s 139us/step - loss: 0.1242 - acc: 0.9720\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 0s 118us/step - loss: 0.1163 - acc: 0.9730\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.1118 - acc: 0.9790\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.1101 - acc: 0.9750\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 0s 104us/step - loss: 0.1092 - acc: 0.9780\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.1078 - acc: 0.9750\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - 0s 208us/step - loss: 0.1029 - acc: 0.9780\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.1020 - acc: 0.9770\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.1015 - acc: 0.9770\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 0s 224us/step - loss: 0.0998 - acc: 0.9750\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 0s 259us/step - loss: 0.0964 - acc: 0.9780\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 0s 149us/step - loss: 0.0944 - acc: 0.9770\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 0s 149us/step - loss: 0.0942 - acc: 0.9780\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0928 - acc: 0.9770\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.0918 - acc: 0.9780\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0942 - acc: 0.9760\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 0s 112us/step - loss: 0.0923 - acc: 0.9750\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - 0s 116us/step - loss: 0.1021 - acc: 0.9670\n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0898 - acc: 0.9760\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 0s 176us/step - loss: 0.0870 - acc: 0.9770\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0917 - acc: 0.9730\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 0s 184us/step - loss: 0.0936 - acc: 0.9690\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.0987 - acc: 0.9660\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 0s 274us/step - loss: 0.0847 - acc: 0.9740\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 0s 181us/step - loss: 0.0825 - acc: 0.9780\n",
      "Epoch 49/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0813 - acc: 0.9750\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0871 - acc: 0.9750\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0848 - acc: 0.9760\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 0s 308us/step - loss: 0.0796 - acc: 0.9760\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 0s 252us/step - loss: 0.0783 - acc: 0.9770\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 0s 116us/step - loss: 0.0793 - acc: 0.9770\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 0s 197us/step - loss: 0.0822 - acc: 0.9760\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 0s 176us/step - loss: 0.0847 - acc: 0.9710\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 0s 104us/step - loss: 0.0774 - acc: 0.9750\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0761 - acc: 0.9790\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 0s 184us/step - loss: 0.0763 - acc: 0.9740\n",
      "Epoch 60/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0811 - acc: 0.9730\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0745 - acc: 0.9770\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.0748 - acc: 0.9780\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.0714 - acc: 0.9780\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 0s 328us/step - loss: 0.0744 - acc: 0.9730 0s - loss: 0.0928 - acc: 0\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 0s 329us/step - loss: 0.0773 - acc: 0.9770\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0776 - acc: 0.976 - 0s 310us/step - loss: 0.0742 - acc: 0.9810\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 0s 313us/step - loss: 0.0733 - acc: 0.9760\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - 0s 186us/step - loss: 0.0730 - acc: 0.9810\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 0s 204us/step - loss: 0.0767 - acc: 0.9760\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.0740 - acc: 0.9730\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0763 - acc: 0.9720\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0728 - acc: 0.9760\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0708 - acc: 0.9780\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 0s 220us/step - loss: 0.0737 - acc: 0.9750\n",
      "Epoch 75/500\n",
      "1000/1000 [==============================] - 0s 269us/step - loss: 0.0743 - acc: 0.9730\n",
      "Epoch 76/500\n",
      "1000/1000 [==============================] - 0s 304us/step - loss: 0.0744 - acc: 0.9700\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0706 - acc: 0.9740\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 0s 132us/step - loss: 0.0725 - acc: 0.9740\n",
      "Epoch 79/500\n",
      "1000/1000 [==============================] - 0s 132us/step - loss: 0.0684 - acc: 0.9770\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0707 - acc: 0.9750\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0682 - acc: 0.9790\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0691 - acc: 0.9760\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0681 - acc: 0.9740\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0707 - acc: 0.9740\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0770 - acc: 0.9730\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0755 - acc: 0.9740\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0673 - acc: 0.9780\n",
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.0699 - acc: 0.9740\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 0.0692 - acc: 0.9760\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0712 - acc: 0.9780\n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0856 - acc: 0.9680\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.0738 - acc: 0.9720\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 0s 112us/step - loss: 0.0680 - acc: 0.9770\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 0s 122us/step - loss: 0.0678 - acc: 0.9760\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0728 - acc: 0.9740\n",
      "Epoch 96/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0790 - acc: 0.9700\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0789 - acc: 0.9680\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0662 - acc: 0.9760\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0679 - acc: 0.9720\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0708 - acc: 0.9740\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0726 - acc: 0.9730\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0638 - acc: 0.9770\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0676 - acc: 0.9770\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0649 - acc: 0.9790\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 0.0723 - acc: 0.9750\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0700 - acc: 0.9750\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 0s 200us/step - loss: 0.0891 - acc: 0.9670\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 0s 220us/step - loss: 0.0740 - acc: 0.9720\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.0732 - acc: 0.9760\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 0s 180us/step - loss: 0.0752 - acc: 0.9680\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.0675 - acc: 0.9770\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 0s 220us/step - loss: 0.0721 - acc: 0.9770\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 0s 184us/step - loss: 0.0650 - acc: 0.9780 0s - loss: 0.0680 - acc: 0.9\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 0s 256us/step - loss: 0.0644 - acc: 0.9810\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 0s 244us/step - loss: 0.0681 - acc: 0.9770\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 0s 252us/step - loss: 0.0738 - acc: 0.9690\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 0s 358us/step - loss: 0.0708 - acc: 0.9700 0s - loss: 0.0752 - acc: 0.967\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 0s 353us/step - loss: 0.0652 - acc: 0.9770\n",
      "Epoch 119/500\n",
      "1000/1000 [==============================] - 0s 277us/step - loss: 0.0650 - acc: 0.9750\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.0677 - acc: 0.9730\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 0s 276us/step - loss: 0.0635 - acc: 0.9780\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 0s 279us/step - loss: 0.0650 - acc: 0.9750\n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 0s 356us/step - loss: 0.0735 - acc: 0.9760\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 0s 379us/step - loss: 0.0749 - acc: 0.9700\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 0s 294us/step - loss: 0.0685 - acc: 0.9770\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 0s 287us/step - loss: 0.0730 - acc: 0.9720\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 0s 228us/step - loss: 0.0631 - acc: 0.9770\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.0688 - acc: 0.9740\n",
      "Epoch 129/500\n",
      "1000/1000 [==============================] - 0s 354us/step - loss: 0.0757 - acc: 0.9740\n",
      "Epoch 130/500\n",
      "1000/1000 [==============================] - 0s 290us/step - loss: 0.0670 - acc: 0.9790 0s - loss: 0.0664 - acc: 0.98\n",
      "Epoch 131/500\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.0625 - acc: 0.9770\n",
      "Epoch 132/500\n",
      "1000/1000 [==============================] - 0s 346us/step - loss: 0.0648 - acc: 0.9740\n",
      "Epoch 133/500\n",
      "1000/1000 [==============================] - 0s 306us/step - loss: 0.0686 - acc: 0.9720\n",
      "Epoch 134/500\n",
      "1000/1000 [==============================] - 0s 215us/step - loss: 0.0659 - acc: 0.9780\n",
      "Epoch 135/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0690 - acc: 0.9730\n",
      "Epoch 136/500\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 0.0640 - acc: 0.9770\n",
      "Epoch 137/500\n",
      "1000/1000 [==============================] - 0s 132us/step - loss: 0.0735 - acc: 0.9720\n",
      "Epoch 138/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0732 - acc: 0.9760\n",
      "Epoch 139/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0628 - acc: 0.9780\n",
      "Epoch 140/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0664 - acc: 0.9780\n",
      "Epoch 141/500\n",
      "1000/1000 [==============================] - 0s 180us/step - loss: 0.0632 - acc: 0.9750\n",
      "Epoch 142/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0709 - acc: 0.9740\n",
      "Epoch 143/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0652 - acc: 0.9790\n",
      "Epoch 144/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0816 - acc: 0.9720\n",
      "Epoch 145/500\n",
      "1000/1000 [==============================] - 0s 280us/step - loss: 0.0726 - acc: 0.9710\n",
      "Epoch 146/500\n",
      "1000/1000 [==============================] - 0s 288us/step - loss: 0.0707 - acc: 0.9750\n",
      "Epoch 147/500\n",
      "1000/1000 [==============================] - 0s 392us/step - loss: 0.0805 - acc: 0.9680 0s - loss: 0.0923 - acc: 0\n",
      "Epoch 148/500\n",
      "1000/1000 [==============================] - 0s 189us/step - loss: 0.0608 - acc: 0.9780\n",
      "Epoch 149/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0635 - acc: 0.9770\n",
      "Epoch 150/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0647 - acc: 0.9740\n",
      "Epoch 151/500\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.0662 - acc: 0.9710\n",
      "Epoch 152/500\n",
      "1000/1000 [==============================] - 0s 208us/step - loss: 0.0647 - acc: 0.9760\n",
      "Epoch 153/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0679 - acc: 0.9730\n",
      "Epoch 154/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0643 - acc: 0.9770\n",
      "Epoch 155/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0683 - acc: 0.9760\n",
      "Epoch 156/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0687 - acc: 0.9720\n",
      "Epoch 157/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0640 - acc: 0.9750\n",
      "Epoch 158/500\n",
      "1000/1000 [==============================] - 0s 132us/step - loss: 0.0615 - acc: 0.9770\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0625 - acc: 0.9770\n",
      "Epoch 160/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0717 - acc: 0.9720\n",
      "Epoch 161/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0647 - acc: 0.9740\n",
      "Epoch 162/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0616 - acc: 0.9740\n",
      "Epoch 163/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0673 - acc: 0.9790\n",
      "Epoch 164/500\n",
      "1000/1000 [==============================] - 0s 184us/step - loss: 0.0730 - acc: 0.9710\n",
      "Epoch 165/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0660 - acc: 0.9790\n",
      "Epoch 166/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0687 - acc: 0.9740\n",
      "Epoch 167/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0705 - acc: 0.9740\n",
      "Epoch 168/500\n",
      "1000/1000 [==============================] - 0s 108us/step - loss: 0.0656 - acc: 0.9780\n",
      "Epoch 169/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0679 - acc: 0.9780\n",
      "Epoch 170/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0777 - acc: 0.9650\n",
      "Epoch 171/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0720 - acc: 0.9710\n",
      "Epoch 172/500\n",
      "1000/1000 [==============================] - 0s 180us/step - loss: 0.0641 - acc: 0.9710\n",
      "Epoch 173/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0724 - acc: 0.9710\n",
      "Epoch 174/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0654 - acc: 0.9770\n",
      "Epoch 175/500\n",
      "1000/1000 [==============================] - 0s 248us/step - loss: 0.0748 - acc: 0.9730\n",
      "Epoch 176/500\n",
      "1000/1000 [==============================] - 0s 200us/step - loss: 0.0672 - acc: 0.9730\n",
      "Epoch 177/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0680 - acc: 0.9760\n",
      "Epoch 178/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0803 - acc: 0.9670\n",
      "Epoch 179/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0642 - acc: 0.9760\n",
      "Epoch 180/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0708 - acc: 0.9710\n",
      "Epoch 181/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0663 - acc: 0.9760\n",
      "Epoch 182/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0673 - acc: 0.9760\n",
      "Epoch 183/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0682 - acc: 0.9730\n",
      "Epoch 184/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0608 - acc: 0.9780\n",
      "Epoch 185/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0625 - acc: 0.9750\n",
      "Epoch 186/500\n",
      "1000/1000 [==============================] - 0s 224us/step - loss: 0.0700 - acc: 0.9720\n",
      "Epoch 187/500\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 0.0645 - acc: 0.9760\n",
      "Epoch 188/500\n",
      "1000/1000 [==============================] - 0s 264us/step - loss: 0.0639 - acc: 0.9760\n",
      "Epoch 189/500\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.0699 - acc: 0.9700\n",
      "Epoch 190/500\n",
      "1000/1000 [==============================] - 0s 260us/step - loss: 0.0771 - acc: 0.9710\n",
      "Epoch 191/500\n",
      "1000/1000 [==============================] - 0s 224us/step - loss: 0.0728 - acc: 0.9720\n",
      "Epoch 192/500\n",
      "1000/1000 [==============================] - 0s 256us/step - loss: 0.0761 - acc: 0.9710\n",
      "Epoch 193/500\n",
      "1000/1000 [==============================] - 0s 264us/step - loss: 0.0663 - acc: 0.9770\n",
      "Epoch 194/500\n",
      "1000/1000 [==============================] - 0s 272us/step - loss: 0.0648 - acc: 0.9740\n",
      "Epoch 195/500\n",
      "1000/1000 [==============================] - 0s 272us/step - loss: 0.0658 - acc: 0.9750\n",
      "Epoch 196/500\n",
      "1000/1000 [==============================] - 0s 231us/step - loss: 0.0711 - acc: 0.9700\n",
      "Epoch 197/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0647 - acc: 0.9760\n",
      "Epoch 198/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0642 - acc: 0.9800\n",
      "Epoch 199/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0612 - acc: 0.9760\n",
      "Epoch 200/500\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0711 - acc: 0.9720\n",
      "Epoch 201/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0900 - acc: 0.9580\n",
      "Epoch 202/500\n",
      "1000/1000 [==============================] - 0s 112us/step - loss: 0.0916 - acc: 0.9680\n",
      "Epoch 203/500\n",
      "1000/1000 [==============================] - 0s 104us/step - loss: 0.0672 - acc: 0.9750\n",
      "Epoch 204/500\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.0809 - acc: 0.9670\n",
      "Epoch 205/500\n",
      "1000/1000 [==============================] - 0s 308us/step - loss: 0.0639 - acc: 0.9730\n",
      "Epoch 206/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0676 - acc: 0.9750\n",
      "Epoch 207/500\n",
      "1000/1000 [==============================] - 0s 184us/step - loss: 0.0681 - acc: 0.9730\n",
      "Epoch 208/500\n",
      "1000/1000 [==============================] - 0s 292us/step - loss: 0.0626 - acc: 0.9790\n",
      "Epoch 209/500\n",
      "1000/1000 [==============================] - 0s 176us/step - loss: 0.0649 - acc: 0.9750\n",
      "Epoch 210/500\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 0.0674 - acc: 0.9720\n",
      "Epoch 211/500\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0681 - acc: 0.9750\n",
      "Epoch 212/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0694 - acc: 0.9680\n",
      "Epoch 213/500\n",
      "1000/1000 [==============================] - 0s 132us/step - loss: 0.0612 - acc: 0.9760\n",
      "Epoch 214/500\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0669 - acc: 0.9780\n",
      "Epoch 215/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0624 - acc: 0.9780\n",
      "Epoch 216/500\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0651 - acc: 0.9790\n",
      "Epoch 217/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0645 - acc: 0.9760\n",
      "Epoch 218/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0743 - acc: 0.9710\n",
      "Epoch 219/500\n",
      "1000/1000 [==============================] - 0s 256us/step - loss: 0.0641 - acc: 0.9730\n",
      "Epoch 220/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0628 - acc: 0.9770\n",
      "Epoch 221/500\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 0.0676 - acc: 0.9730\n",
      "Epoch 222/500\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0808 - acc: 0.9640\n",
      "Epoch 223/500\n",
      "1000/1000 [==============================] - 0s 136us/step - loss: 0.0604 - acc: 0.9770\n",
      "Epoch 224/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0632 - acc: 0.9780\n",
      "Epoch 225/500\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.0670 - acc: 0.9760\n",
      "Epoch 226/500\n",
      "1000/1000 [==============================] - 0s 224us/step - loss: 0.0658 - acc: 0.9680\n",
      "Epoch 227/500\n",
      "1000/1000 [==============================] - 0s 180us/step - loss: 0.0648 - acc: 0.9770\n",
      "Epoch 228/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0848 - acc: 0.9630\n",
      "Epoch 229/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0767 - acc: 0.9690\n",
      "Epoch 230/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0680 - acc: 0.9720\n",
      "Epoch 231/500\n",
      "1000/1000 [==============================] - 0s 180us/step - loss: 0.0681 - acc: 0.9760\n",
      "Epoch 232/500\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.0688 - acc: 0.9740\n",
      "Epoch 233/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.0606 - acc: 0.9770\n",
      "Epoch 234/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.0611 - acc: 0.9750\n",
      "Epoch 235/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.0670 - acc: 0.9720\n",
      "Epoch 236/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0764 - acc: 0.9670\n",
      "Epoch 237/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0701 - acc: 0.9760\n",
      "Epoch 238/500\n",
      "1000/1000 [==============================] - 0s 176us/step - loss: 0.0718 - acc: 0.9730\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0609 - acc: 0.9790\n",
      "Epoch 240/500\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.0617 - acc: 0.9760\n",
      "Epoch 241/500\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.0640 - acc: 0.9770\n",
      "Epoch 242/500\n",
      "1000/1000 [==============================] - 0s 198us/step - loss: 0.0635 - acc: 0.9780\n",
      "Epoch 243/500\n",
      "1000/1000 [==============================] - 0s 176us/step - loss: 0.0849 - acc: 0.9630\n",
      "Epoch 244/500\n",
      "1000/1000 [==============================] - 0s 208us/step - loss: 0.0734 - acc: 0.9710\n",
      "Epoch 245/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0653 - acc: 0.9760\n",
      "Epoch 246/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0651 - acc: 0.9750\n",
      "Epoch 247/500\n",
      "1000/1000 [==============================] - 0s 132us/step - loss: 0.0660 - acc: 0.9740\n",
      "Epoch 248/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0705 - acc: 0.9730\n",
      "Epoch 249/500\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.0616 - acc: 0.9750\n",
      "Epoch 250/500\n",
      "1000/1000 [==============================] - 0s 184us/step - loss: 0.0656 - acc: 0.9760\n",
      "Epoch 251/500\n",
      "1000/1000 [==============================] - 0s 166us/step - loss: 0.0618 - acc: 0.9790\n",
      "Epoch 252/500\n",
      "1000/1000 [==============================] - 0s 184us/step - loss: 0.0640 - acc: 0.9760\n",
      "Epoch 253/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0679 - acc: 0.9750\n",
      "Epoch 254/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0614 - acc: 0.9770\n",
      "Epoch 255/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0729 - acc: 0.9750\n",
      "Epoch 256/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0758 - acc: 0.9720\n",
      "Epoch 257/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0657 - acc: 0.9760\n",
      "Epoch 258/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0657 - acc: 0.9750\n",
      "Epoch 259/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0608 - acc: 0.9790\n",
      "Epoch 260/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0666 - acc: 0.9770\n",
      "Epoch 261/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0620 - acc: 0.9760\n",
      "Epoch 262/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0585 - acc: 0.9810\n",
      "Epoch 263/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0662 - acc: 0.9760\n",
      "Epoch 264/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0616 - acc: 0.9760\n",
      "Epoch 265/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0608 - acc: 0.9780\n",
      "Epoch 266/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0607 - acc: 0.9780\n",
      "Epoch 267/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0657 - acc: 0.9750\n",
      "Epoch 268/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0646 - acc: 0.9750\n",
      "Epoch 269/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0701 - acc: 0.9760\n",
      "Epoch 270/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0712 - acc: 0.9710\n",
      "Epoch 271/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0708 - acc: 0.9750\n",
      "Epoch 272/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0717 - acc: 0.9690\n",
      "Epoch 273/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0870 - acc: 0.9640\n",
      "Epoch 274/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0793 - acc: 0.9670\n",
      "Epoch 275/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0712 - acc: 0.9770\n",
      "Epoch 276/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0603 - acc: 0.9750\n",
      "Epoch 277/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0638 - acc: 0.9760\n",
      "Epoch 278/500\n",
      "1000/1000 [==============================] - 0s 176us/step - loss: 0.0629 - acc: 0.9760\n",
      "Epoch 279/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0709 - acc: 0.9720\n",
      "Epoch 280/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0691 - acc: 0.9760\n",
      "Epoch 281/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0670 - acc: 0.9690\n",
      "Epoch 282/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0628 - acc: 0.9780\n",
      "Epoch 283/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0612 - acc: 0.9780\n",
      "Epoch 284/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0643 - acc: 0.9760\n",
      "Epoch 285/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0722 - acc: 0.9690\n",
      "Epoch 286/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0700 - acc: 0.9740\n",
      "Epoch 287/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0794 - acc: 0.9680\n",
      "Epoch 288/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0623 - acc: 0.9740\n",
      "Epoch 289/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0635 - acc: 0.9750\n",
      "Epoch 290/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0638 - acc: 0.9770\n",
      "Epoch 291/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0668 - acc: 0.9760\n",
      "Epoch 292/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0702 - acc: 0.9720\n",
      "Epoch 293/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0687 - acc: 0.9740\n",
      "Epoch 294/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0645 - acc: 0.9770\n",
      "Epoch 295/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0817 - acc: 0.9660\n",
      "Epoch 296/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0594 - acc: 0.9780\n",
      "Epoch 297/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0761 - acc: 0.9690\n",
      "Epoch 298/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0622 - acc: 0.9760\n",
      "Epoch 299/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0612 - acc: 0.9780\n",
      "Epoch 300/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.0725 - acc: 0.9710\n",
      "Epoch 301/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0614 - acc: 0.9760\n",
      "Epoch 302/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0621 - acc: 0.9780\n",
      "Epoch 303/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0784 - acc: 0.9730\n",
      "Epoch 304/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0816 - acc: 0.9680\n",
      "Epoch 305/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0739 - acc: 0.9700\n",
      "Epoch 306/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0737 - acc: 0.9730\n",
      "Epoch 307/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0654 - acc: 0.9770\n",
      "Epoch 308/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0643 - acc: 0.9770\n",
      "Epoch 309/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0644 - acc: 0.9750\n",
      "Epoch 310/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0701 - acc: 0.9730\n",
      "Epoch 311/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0706 - acc: 0.9730\n",
      "Epoch 312/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0672 - acc: 0.9770\n",
      "Epoch 313/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0618 - acc: 0.9760\n",
      "Epoch 314/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0652 - acc: 0.9740\n",
      "Epoch 315/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0659 - acc: 0.9740\n",
      "Epoch 316/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0608 - acc: 0.9750\n",
      "Epoch 317/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0619 - acc: 0.9750\n",
      "Epoch 318/500\n",
      "1000/1000 [==============================] - 0s 175us/step - loss: 0.0679 - acc: 0.9770\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0792 - acc: 0.9670\n",
      "Epoch 320/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0660 - acc: 0.9730\n",
      "Epoch 321/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0647 - acc: 0.9710\n",
      "Epoch 322/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0619 - acc: 0.9760\n",
      "Epoch 323/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0658 - acc: 0.9750\n",
      "Epoch 324/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0615 - acc: 0.9780\n",
      "Epoch 325/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0616 - acc: 0.9780\n",
      "Epoch 326/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0658 - acc: 0.9730\n",
      "Epoch 327/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0641 - acc: 0.9770\n",
      "Epoch 328/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0604 - acc: 0.9770\n",
      "Epoch 329/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0621 - acc: 0.9760\n",
      "Epoch 330/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0625 - acc: 0.9770\n",
      "Epoch 331/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0788 - acc: 0.9700\n",
      "Epoch 332/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0631 - acc: 0.9770\n",
      "Epoch 333/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0641 - acc: 0.9750\n",
      "Epoch 334/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0648 - acc: 0.9760\n",
      "Epoch 335/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0830 - acc: 0.9680\n",
      "Epoch 336/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0707 - acc: 0.9720\n",
      "Epoch 337/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0761 - acc: 0.9700\n",
      "Epoch 338/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0655 - acc: 0.9780\n",
      "Epoch 339/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0613 - acc: 0.9770\n",
      "Epoch 340/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0665 - acc: 0.9720\n",
      "Epoch 341/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0631 - acc: 0.9760\n",
      "Epoch 342/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0674 - acc: 0.9730\n",
      "Epoch 343/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0651 - acc: 0.9760\n",
      "Epoch 344/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0723 - acc: 0.9760\n",
      "Epoch 345/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0648 - acc: 0.9750\n",
      "Epoch 346/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0666 - acc: 0.9750\n",
      "Epoch 347/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0662 - acc: 0.9710\n",
      "Epoch 348/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0652 - acc: 0.9780\n",
      "Epoch 349/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0712 - acc: 0.9750\n",
      "Epoch 350/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0740 - acc: 0.9770\n",
      "Epoch 351/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0641 - acc: 0.9760\n",
      "Epoch 352/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0684 - acc: 0.9800\n",
      "Epoch 353/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0726 - acc: 0.9730\n",
      "Epoch 354/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0641 - acc: 0.9760\n",
      "Epoch 355/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0681 - acc: 0.9750\n",
      "Epoch 356/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0668 - acc: 0.972 - 0s 148us/step - loss: 0.0679 - acc: 0.9740\n",
      "Epoch 357/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0742 - acc: 0.9640\n",
      "Epoch 358/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0632 - acc: 0.9740\n",
      "Epoch 359/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0717 - acc: 0.9730\n",
      "Epoch 360/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0674 - acc: 0.9770\n",
      "Epoch 361/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0711 - acc: 0.9700\n",
      "Epoch 362/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0608 - acc: 0.9780\n",
      "Epoch 363/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0656 - acc: 0.9760\n",
      "Epoch 364/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0702 - acc: 0.9740\n",
      "Epoch 365/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0725 - acc: 0.9770\n",
      "Epoch 366/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0650 - acc: 0.9750\n",
      "Epoch 367/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0650 - acc: 0.9710\n",
      "Epoch 368/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0642 - acc: 0.9770\n",
      "Epoch 369/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0623 - acc: 0.9790\n",
      "Epoch 370/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0631 - acc: 0.9770\n",
      "Epoch 371/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0647 - acc: 0.9760\n",
      "Epoch 372/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0637 - acc: 0.9720\n",
      "Epoch 373/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0630 - acc: 0.9770\n",
      "Epoch 374/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0620 - acc: 0.9760\n",
      "Epoch 375/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0643 - acc: 0.9780\n",
      "Epoch 376/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0634 - acc: 0.9790\n",
      "Epoch 377/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0806 - acc: 0.9650\n",
      "Epoch 378/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0650 - acc: 0.9720\n",
      "Epoch 379/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0612 - acc: 0.9760\n",
      "Epoch 380/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0718 - acc: 0.9750\n",
      "Epoch 381/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0582 - acc: 0.9800\n",
      "Epoch 382/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0741 - acc: 0.9720\n",
      "Epoch 383/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0693 - acc: 0.9720\n",
      "Epoch 384/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0671 - acc: 0.9750\n",
      "Epoch 385/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0642 - acc: 0.9780\n",
      "Epoch 386/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0636 - acc: 0.9770\n",
      "Epoch 387/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0798 - acc: 0.9660\n",
      "Epoch 388/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0703 - acc: 0.9760\n",
      "Epoch 389/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0684 - acc: 0.9700\n",
      "Epoch 390/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0626 - acc: 0.9770\n",
      "Epoch 391/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0648 - acc: 0.9780\n",
      "Epoch 392/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0645 - acc: 0.9740\n",
      "Epoch 393/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0647 - acc: 0.9770\n",
      "Epoch 394/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0723 - acc: 0.9750\n",
      "Epoch 395/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0715 - acc: 0.9750\n",
      "Epoch 396/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0627 - acc: 0.9750\n",
      "Epoch 397/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0655 - acc: 0.9740\n",
      "Epoch 398/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0623 - acc: 0.9750\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0720 - acc: 0.9730\n",
      "Epoch 400/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0620 - acc: 0.9780\n",
      "Epoch 401/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0630 - acc: 0.9740\n",
      "Epoch 402/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0646 - acc: 0.9760\n",
      "Epoch 403/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0699 - acc: 0.9720\n",
      "Epoch 404/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0732 - acc: 0.9740\n",
      "Epoch 405/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0761 - acc: 0.9720\n",
      "Epoch 406/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0683 - acc: 0.9700\n",
      "Epoch 407/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0643 - acc: 0.9800\n",
      "Epoch 408/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0669 - acc: 0.9770\n",
      "Epoch 409/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0640 - acc: 0.9760\n",
      "Epoch 410/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0611 - acc: 0.9760\n",
      "Epoch 411/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0626 - acc: 0.9780\n",
      "Epoch 412/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0631 - acc: 0.9760\n",
      "Epoch 413/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0613 - acc: 0.9790\n",
      "Epoch 414/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0610 - acc: 0.9760\n",
      "Epoch 415/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0636 - acc: 0.9740\n",
      "Epoch 416/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0733 - acc: 0.9720\n",
      "Epoch 417/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0669 - acc: 0.9730\n",
      "Epoch 418/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0653 - acc: 0.9750\n",
      "Epoch 419/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0638 - acc: 0.9750\n",
      "Epoch 420/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0687 - acc: 0.9720\n",
      "Epoch 421/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0654 - acc: 0.9720\n",
      "Epoch 422/500\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.0673 - acc: 0.9730\n",
      "Epoch 423/500\n",
      "1000/1000 [==============================] - 0s 180us/step - loss: 0.0720 - acc: 0.9720\n",
      "Epoch 424/500\n",
      "1000/1000 [==============================] - 0s 176us/step - loss: 0.0649 - acc: 0.9780\n",
      "Epoch 425/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.0627 - acc: 0.9770\n",
      "Epoch 426/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0645 - acc: 0.9750\n",
      "Epoch 427/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0638 - acc: 0.9750\n",
      "Epoch 428/500\n",
      "1000/1000 [==============================] - 0s 148us/step - loss: 0.0690 - acc: 0.9750\n",
      "Epoch 429/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0648 - acc: 0.9750\n",
      "Epoch 430/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0676 - acc: 0.9740\n",
      "Epoch 431/500\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.0715 - acc: 0.9710 0s - loss: 0.0659 - acc: 0.973\n",
      "Epoch 432/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.0626 - acc: 0.9760\n",
      "Epoch 433/500\n",
      "1000/1000 [==============================] - 0s 202us/step - loss: 0.0662 - acc: 0.9780\n",
      "Epoch 434/500\n",
      "1000/1000 [==============================] - 0s 193us/step - loss: 0.0656 - acc: 0.9750\n",
      "Epoch 435/500\n",
      "1000/1000 [==============================] - 0s 200us/step - loss: 0.0628 - acc: 0.9810\n",
      "Epoch 436/500\n",
      "1000/1000 [==============================] - 0s 224us/step - loss: 0.0716 - acc: 0.9700\n",
      "Epoch 437/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0610 - acc: 0.9740\n",
      "Epoch 438/500\n",
      "1000/1000 [==============================] - 0s 160us/step - loss: 0.0615 - acc: 0.9770\n",
      "Epoch 439/500\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.0646 - acc: 0.9740\n",
      "Epoch 440/500\n",
      "1000/1000 [==============================] - 0s 200us/step - loss: 0.0642 - acc: 0.9770\n",
      "Epoch 441/500\n",
      "1000/1000 [==============================] - 0s 200us/step - loss: 0.0613 - acc: 0.9750\n",
      "Epoch 442/500\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.0624 - acc: 0.9770\n",
      "Epoch 443/500\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.0626 - acc: 0.9780\n",
      "Epoch 444/500\n",
      "1000/1000 [==============================] - 0s 204us/step - loss: 0.0613 - acc: 0.9780\n",
      "Epoch 445/500\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0712 - acc: 0.9720\n",
      "Epoch 446/500\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.0612 - acc: 0.9750\n",
      "Epoch 447/500\n",
      "1000/1000 [==============================] - 0s 124us/step - loss: 0.0640 - acc: 0.9720\n",
      "Epoch 448/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.0700 - acc: 0.9740\n",
      "Epoch 449/500\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.0682 - acc: 0.9750\n",
      "Epoch 450/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.0670 - acc: 0.9770\n",
      "Epoch 451/500\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.0789 - acc: 0.9710\n",
      "Epoch 452/500\n",
      "1000/1000 [==============================] - 0s 184us/step - loss: 0.0670 - acc: 0.9720\n",
      "Epoch 453/500\n",
      "1000/1000 [==============================] - 0s 204us/step - loss: 0.0629 - acc: 0.9770\n",
      "Epoch 454/500\n",
      "1000/1000 [==============================] - 0s 164us/step - loss: 0.0716 - acc: 0.9770\n",
      "Epoch 455/500\n",
      "1000/1000 [==============================] - 0s 200us/step - loss: 0.0652 - acc: 0.9750\n",
      "Epoch 456/500\n",
      "1000/1000 [==============================] - 0s 215us/step - loss: 0.0782 - acc: 0.9690\n",
      "Epoch 457/500\n",
      "1000/1000 [==============================] - 0s 154us/step - loss: 0.0728 - acc: 0.9690\n",
      "Epoch 458/500\n",
      "1000/1000 [==============================] - 0s 150us/step - loss: 0.0673 - acc: 0.9750\n",
      "Epoch 459/500\n",
      "1000/1000 [==============================] - 0s 159us/step - loss: 0.0646 - acc: 0.9780\n",
      "Epoch 460/500\n",
      "1000/1000 [==============================] - 0s 176us/step - loss: 0.0628 - acc: 0.9730\n",
      "Epoch 461/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0666 - acc: 0.9770\n",
      "Epoch 462/500\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 0.1010 - acc: 0.9590\n",
      "Epoch 463/500\n",
      "1000/1000 [==============================] - 0s 180us/step - loss: 0.0762 - acc: 0.9720\n",
      "Epoch 464/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0743 - acc: 0.9720\n",
      "Epoch 465/500\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 0.0734 - acc: 0.9690\n",
      "Epoch 466/500\n",
      "1000/1000 [==============================] - 0s 208us/step - loss: 0.0647 - acc: 0.9730\n",
      "Epoch 467/500\n",
      "1000/1000 [==============================] - 0s 263us/step - loss: 0.0677 - acc: 0.9760\n",
      "Epoch 468/500\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 0.0650 - acc: 0.9760\n",
      "Epoch 469/500\n",
      "1000/1000 [==============================] - 0s 198us/step - loss: 0.0681 - acc: 0.9740\n",
      "Epoch 470/500\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.0640 - acc: 0.9730\n",
      "Epoch 471/500\n",
      "1000/1000 [==============================] - 0s 228us/step - loss: 0.0663 - acc: 0.9740\n",
      "Epoch 472/500\n",
      "1000/1000 [==============================] - 0s 207us/step - loss: 0.0703 - acc: 0.9720\n",
      "Epoch 473/500\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.0765 - acc: 0.9650\n",
      "Epoch 474/500\n",
      "1000/1000 [==============================] - 0s 182us/step - loss: 0.0763 - acc: 0.9690\n",
      "Epoch 475/500\n",
      "1000/1000 [==============================] - 0s 161us/step - loss: 0.0653 - acc: 0.9770\n",
      "Epoch 476/500\n",
      "1000/1000 [==============================] - 0s 131us/step - loss: 0.0622 - acc: 0.9760\n",
      "Epoch 477/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0766 - acc: 0.9720\n",
      "Epoch 478/500\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 0.0698 - acc: 0.9730\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 188us/step - loss: 0.0618 - acc: 0.9770\n",
      "Epoch 480/500\n",
      "1000/1000 [==============================] - 0s 180us/step - loss: 0.0645 - acc: 0.9750\n",
      "Epoch 481/500\n",
      "1000/1000 [==============================] - 0s 152us/step - loss: 0.0696 - acc: 0.9730\n",
      "Epoch 482/500\n",
      "1000/1000 [==============================] - 0s 142us/step - loss: 0.0651 - acc: 0.9760\n",
      "Epoch 483/500\n",
      "1000/1000 [==============================] - 0s 150us/step - loss: 0.0651 - acc: 0.9770\n",
      "Epoch 484/500\n",
      "1000/1000 [==============================] - 0s 163us/step - loss: 0.0637 - acc: 0.9750\n",
      "Epoch 485/500\n",
      "1000/1000 [==============================] - 0s 190us/step - loss: 0.0909 - acc: 0.9710\n",
      "Epoch 486/500\n",
      "1000/1000 [==============================] - 0s 208us/step - loss: 0.0686 - acc: 0.9780\n",
      "Epoch 487/500\n",
      "1000/1000 [==============================] - 0s 168us/step - loss: 0.0722 - acc: 0.9730\n",
      "Epoch 488/500\n",
      "1000/1000 [==============================] - 0s 156us/step - loss: 0.0699 - acc: 0.9730\n",
      "Epoch 489/500\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.0668 - acc: 0.9750\n",
      "Epoch 490/500\n",
      "1000/1000 [==============================] - 0s 119us/step - loss: 0.0629 - acc: 0.9780\n",
      "Epoch 491/500\n",
      "1000/1000 [==============================] - 0s 115us/step - loss: 0.0649 - acc: 0.9770\n",
      "Epoch 492/500\n",
      "1000/1000 [==============================] - 0s 122us/step - loss: 0.0648 - acc: 0.9780\n",
      "Epoch 493/500\n",
      "1000/1000 [==============================] - 0s 123us/step - loss: 0.0649 - acc: 0.9750\n",
      "Epoch 494/500\n",
      "1000/1000 [==============================] - 0s 126us/step - loss: 0.0770 - acc: 0.9700\n",
      "Epoch 495/500\n",
      "1000/1000 [==============================] - 0s 132us/step - loss: 0.0628 - acc: 0.9750\n",
      "Epoch 496/500\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0674 - acc: 0.9740\n",
      "Epoch 497/500\n",
      "1000/1000 [==============================] - 0s 104us/step - loss: 0.0746 - acc: 0.9740\n",
      "Epoch 498/500\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.0657 - acc: 0.9750\n",
      "Epoch 499/500\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.0698 - acc: 0.9710\n",
      "Epoch 500/500\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.0614 - acc: 0.9760\n",
      "prediction is:  [[0.9999856]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "n_pts = 500\n",
    "np.random.seed(0)\n",
    "Xa = np.array([np.random.normal(13, 2, n_pts),\n",
    "               np.random.normal(12, 2, n_pts)]).T\n",
    "Xb = np.array([np.random.normal(8, 2, n_pts),\n",
    "               np.random.normal(6, 2, n_pts)]).T\n",
    "\n",
    "X = np.vstack((Xa, Xb))\n",
    "y = np.matrix(np.append(np.zeros(n_pts), np.ones(n_pts))).T\n",
    "\n",
    "plt.scatter(X[:n_pts,0], X[:n_pts,1])\n",
    "plt.scatter(X[n_pts:,0], X[n_pts:,1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_shape=(2,), activation='sigmoid'))\n",
    "adam=Adam(lr = 0.1 )\n",
    "model.compile(adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "h=model.fit(x=X, y=y, verbose=1, batch_size=50,epochs=500, shuffle='true')\n",
    "\n",
    "plt.plot(h.history['acc'])\n",
    "\n",
    "plt.legend(['accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.plot(h.history['loss'])\n",
    "plt.legend(['loss'])\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "def plot_decision_boundary(X, y, model):\n",
    "    x_span = np.linspace(min(X[:,0]) - 1, max(X[:,0]) + 1)\n",
    "    y_span = np.linspace(min(X[:,1]) - 1, max(X[:,1]) + 1)\n",
    "    xx, yy = np.meshgrid(x_span, y_span)\n",
    "    xx_, yy_ = xx.ravel(), yy.ravel()\n",
    "    grid = np.c_[xx_, yy_]\n",
    "    pred_func = model.predict(grid)\n",
    "    z = pred_func.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, z)\n",
    "\n",
    "plot_decision_boundary(X, y, model)\n",
    "plt.scatter(X[:n_pts,0], X[:n_pts,1])\n",
    "plt.scatter(X[n_pts:,0], X[n_pts:,1])\n",
    "\n",
    "plot_decision_boundary(X, y, model)\n",
    "plt.scatter(X[:n_pts,0], X[:n_pts,1])\n",
    "plt.scatter(X[n_pts:,0], X[n_pts:,1])\n",
    "\n",
    "x = 7.5\n",
    "y = 5\n",
    "\n",
    "\n",
    "point = np.array([[x, y]])\n",
    "prediction = model.predict(point)\n",
    "plt.plot([x], [y], marker='o', markersize=10, color=\"red\")\n",
    "print(\"prediction is: \",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
